{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SDS M1 - S6",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SDS-AAU/M1-2019/blob/master/notebooks/SDS_M1_S6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnrQ-FwsBqJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installing some libraries that we are goint to use later\n",
        "# seaborn (right version for plotting), hdbscan for clustering and rgeocoder for reverse geocoding offline\n",
        "!pip3 install seaborn==0.9.0 hdbscan rgeocoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axhadLhBtP30",
        "colab_type": "text"
      },
      "source": [
        "# A quick dive into nomad geography and the gig-economy - Unsupervised ML\n",
        "### Roman Jurowetzki - 10/9 - 2019; roman@business.aau.dk\n",
        "\n",
        "In this tutorial you will learn how to work with dimensionality reduction and clustering techniques. We will have a look at data that comes in slightly different shapes and how we can aggregate it to identify latent patterns in a population.\n",
        "\n",
        "We will use a dataset on cities worldwide (same source as the 1. miniassignment)to get familiar with dimensionality reduction.\n",
        "\n",
        "Then, we will use a dataset of jobs performed by 1000 freelance-workers.\n",
        "\n",
        "![](https://www.phocuswire.com/uploadedimages/uploads/2013/04/global-routes.jpg?width=800&height=400&scale=both&mode=crop)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15jNW6FNtZzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pandas handles tabular data\n",
        "import pandas as pd\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x) # turn off scientific notation and too much decimal blah\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "import matplotlib.pyplot as plt # plotting library\n",
        "\n",
        "#Numpy for linear algebra & co\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el2mVQlWvljI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We open the data directly from Github\n",
        "cities = pd.read_csv('https://github.com/SDS-AAU/M1-2019/raw/master/data/nomad_cities.csv', sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ztGcQrTgg4t",
        "colab_type": "text"
      },
      "source": [
        "The data used in this tutorial is taken with permission form https://nomadlist.com/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEuwkuqBLfdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's have a quick look at the imported data\n",
        "cities.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPc5IQM4wabU",
        "colab_type": "text"
      },
      "source": [
        "For some reason (data is messy) we have the name of the city as well as longitude/langitude but we don't have the country or region names.\n",
        "Let's try to fix that.\n",
        "\n",
        "One approach could be based on the lon/lat values, as city names may non-unique.\n",
        "\n",
        "For this we need to start by \"looking up\" the country name for each specific coordinate\n",
        "\n",
        "We can use an offline reverse geocoder package for that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmJujGq3t5bk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load and instantiate the reversegeocoder\n",
        "\n",
        "from rgeocoder import ReverseGeocoder\n",
        "rg = ReverseGeocoder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM76MbgLxH-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# That's how it works\n",
        "\n",
        "location = rg.nearest(56.457, 10.039) #lat, lon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkt3RAc6xjEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's see what we get\n",
        "print(location.name)\n",
        "print(location.admin1)\n",
        "print(location.admin2)\n",
        "print(location.cc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAVWUDIvt-n3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A smart way to get all geocoding done in one line\n",
        "\n",
        "cities['countrycode'] = cities.apply(lambda t: rg.nearest(t['latitude'],t['longitude']).cc, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI2oY7cLyDZy",
        "colab_type": "text"
      },
      "source": [
        "in the above cell we apply the \n",
        "\n",
        "\n",
        "```\n",
        "rg.nearest(t['latitude'],t['longitude']).cc\n",
        "```\n",
        "\n",
        "function to each row t of the dataframe cities\n",
        "\n",
        "\n",
        "```\n",
        "lambda t:\n",
        "```\n",
        "\n",
        "is a rather scary syntactic way of calling an anonymous function\n",
        "\n",
        "Basically, we could say:\n",
        "\n",
        "\n",
        "*   For each row of the cities dataframe\n",
        "*   take the value of the longitude and latitude columns\n",
        "*   look up the corresponding place\n",
        "*   write the country code \"cc\" into a new column \"alpha-2\"\n",
        "\n",
        "Now that we have exact country codes for each city, we need to find the regions these countries belong to\n",
        "\n",
        "Luckily it's easy to find tables listing this information on the internet.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mgLpPyhrgIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download a recent country info table\n",
        "c = pd.read_csv('https://github.com/SDS-AAU/M1-2019/raw/master/data/countrylist.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WEc2iLsvzH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quick check\n",
        "c.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjygH7xqso3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Merge this lookup table with our initial cities list\n",
        " cities = cities.merge(c, left_on='countrycode', right_on='alpha_2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIf50m7-wifL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's select interesting variables for the analysis\n",
        "\n",
        "vars_analysis = [\"cost_nomad\", \"cost_coworking\", \"cost_expat\", \"coffee_in_cafe\", \"cost_beer\", # costs\n",
        "          \"places_to_work\", \"free_wifi_available\", \"internet_speed\", # work\n",
        "          \"freedom_score\", \"peace_score\", \"safety\", \"fragile_states_index\", \"press_freedom_index\", # safety & freedom\n",
        "          \"female_friendly\", \"lgbt_friendly\", \"friendly_to_foreigners\", \"racism\", # friendly\n",
        "          \"leisure\",\"life_score\",\"nightlife\",\"weed\"] # fun \n",
        "\n",
        "vars_descr = [\"nomad_score\", \"cost_nomad\", \"places_to_work\", \"freedom_score\", \"friendly_to_foreigners\", \"life_score\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2PtH_vtwjHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# And use the selection to only extract these variables into a new object\n",
        "\n",
        "data = cities[vars_analysis]\n",
        "\n",
        "descr = cities[vars_descr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfLSyC59yGql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quick check\n",
        "\n",
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2V2EchJ0M4-",
        "colab_type": "text"
      },
      "source": [
        "We can see some strange things going with the data types. Some are floats or ints as we would expect but others are objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb2w3utrx2cI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data['peace_score'].unique())\n",
        "print(data['freedom_score'].unique())\n",
        "print(data['fragile_states_index'].unique())\n",
        "print(data['press_freedom_index'].unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb8RpPuq0cKY",
        "colab_type": "text"
      },
      "source": [
        "This is a problem that probably has something to do with the scraping process. Let's try to turn everything into floats and if we can't we just put in a missing value statement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvu_3-PQy69_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will fo exactly that\n",
        "def floater(x):\n",
        "  try: #Try to\n",
        "    return float(x) #Turn X into a floating point number\n",
        "  except ValueError: #In case a ValueError occurs\n",
        "    return np.nan #Turn X into np.nan (missing value placeholder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJIxog6kzYi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# map applies the defined function to every observation\n",
        "\n",
        "data.loc[:,'peace_score'] = data['peace_score'].map(floater)\n",
        "data.loc[:,'freedom_score'] = data['freedom_score'].map(floater)\n",
        "data.loc[:,'fragile_states_index'] = data['fragile_states_index'].map(floater)\n",
        "data.loc[:,'press_freedom_index'] = data['press_freedom_index'].map(floater)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9xsId4XZkpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# yup, some missing data...\n",
        "data.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtUEVXoy1CgD",
        "colab_type": "text"
      },
      "source": [
        "Now we are facing a new problem - Missing Data. While it would be easier to just kick out these cities, we will try to do better and impute.\n",
        "\n",
        "Read up on imputation in the documentation of the package: https://github.com/iskandr/fancyimpute\n",
        "also here: https://medium.com/ibm-data-science-experience/missing-data-conundrum-exploration-and-imputation-techniques-9f40abe0fd87\n",
        "\n",
        "There are many other packages and modules that perform imputation. I found facyimpute the least problematic so far\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmzRZp7Uz7_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the imputation package\n",
        "from fancyimpute import SoftImpute, SimpleFill"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMIqDDhf0Uss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Easy version: Just replace missing values by the mean of the column\n",
        "data_imp = SimpleFill(fill_method='mean').fit_transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-9vf_9rOSEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can have a quick look\n",
        "pd.DataFrame(data_imp, columns=data.columns).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMIbt_pZ1rgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Or, we go crazy and use a neural network powered method\n",
        "data_imp = SoftImpute().fit_transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyJYlRjE2uox",
        "colab_type": "text"
      },
      "source": [
        "Before doing any kind of machine learning, especially when using neural networks and similar, it is important to normalise the data. One good way of doing it is using standardisation.\n",
        "From each value we substract the sample mean and divide by the standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muuGk6V33kIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's standard-scale our data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "data_scaled = scaler.fit_transform(data_imp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkxRVIPK3CLE",
        "colab_type": "text"
      },
      "source": [
        "As you can see, now our data has a mean of 0 and a standard deviation of one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2cAn_IE4GQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(data_scaled, columns=data.columns).describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AQz1oEv3jWW",
        "colab_type": "text"
      },
      "source": [
        "Let's try out dimensionality reduction with Principle Component Analysis: PCA\n",
        "Check out this for details on PCA: https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html\n",
        "\n",
        "\n",
        "Want to know more about dimensionality reduction?\n",
        "https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9GtwCtv4gNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the module and instantiate a PCA object\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=7) #We pick 7 as the number of components...just because (it's a 3rd of the columns available)\n",
        "\n",
        "# Fit and transform the data\n",
        "data_reduced = pca.fit_transform(data_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52y7Z-Vh49us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure the data shape is as it should be\n",
        "data_reduced.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EgDD340cBGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_data = pd.DataFrame({'evr': pca.explained_variance_ratio_, 'cumsum_evr': np.cumsum(pca.explained_variance_ratio_)}).stack()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIR5W5VY4dpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Is 7 components really a good choice?\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "sns.lineplot(y = plot_data.values, x = plot_data.index.get_level_values(0), hue=plot_data.index.get_level_values(1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClO7TBNL5ODu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How mach \"information\" do we kick out?\n",
        "pca.explained_variance_ratio_.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM2hD2ZXAseQ",
        "colab_type": "text"
      },
      "source": [
        "Reducing the dimensionality is a nice way to make the data more approachable. In the present case, 21 variables is not a large number. However, the initial number of variables may be much higher (as we will see in the next dataset)\n",
        "\n",
        "Now we can cluster the data using the most common and simple K-means algorithm.\n",
        "https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8pglP30hfCa",
        "colab_type": "text"
      },
      "source": [
        "### How many clusters?\n",
        "\n",
        "Elbow - method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbKWseXdhq4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmjAv2uPhdsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inertia = []\n",
        "for i in range(1,11):\n",
        "  k_means = KMeans(n_clusters=i)\n",
        "  inertia.append(k_means.fit(data_reduced).inertia_)\n",
        "\n",
        "sns.lineplot(y = inertia, x = range(1,11))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqdX6ngX5wyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's cluster our data\n",
        "\n",
        "clusterer = KMeans(n_clusters=3)\n",
        "clusterer.fit(data_reduced)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w9zyKypCCtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we can plot in our points with some coloring\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "g = sns.scatterplot(data_reduced[:,0], data_reduced[:,1], hue=clusterer.labels_,\n",
        "               legend='full', palette='viridis')\n",
        "\n",
        "legend = g.get_legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xtJ7uXDiiR_I"
      },
      "source": [
        "We can certainly make things much more fancy. However, as you can see, that will require more work.\n",
        "\n",
        "We can use Bokeh for an interactive visualisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ceBxu0NRiRtO",
        "colab": {}
      },
      "source": [
        "# Load the needed bokeh modules\n",
        "\n",
        "from bokeh.models import ColumnDataSource\n",
        "from bokeh.plotting import figure, show, output_notebook\n",
        "from bokeh.palettes import Spectral6\n",
        "from bokeh.transform import factor_cmap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIpRBucmhaDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the data that we are going to use as a dictionary\n",
        "\n",
        "d = {'y':data_reduced[:,1],'x':data_reduced[:,0], 'place': cities.place, \n",
        "     'cluster': pd.Series(clusterer.labels_).map({0:'a',1:'b',2:'c'}),\n",
        "     'country':cities['alpha_2'],\n",
        "     'region':cities['sub_region']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scGRl3v0o9Rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defineand transform a color-palette\n",
        "\n",
        "colors = factor_cmap('cluster', palette=Spectral6, factors=d['cluster'].unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lfczv6buJ8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform the data to Bokeh format\n",
        "d = ColumnDataSource(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTzYeGheYsjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define interactive tooling and plot for notebook output\n",
        "\n",
        "output_notebook()\n",
        "\n",
        "TOOLS=\"hover,crosshair,pan,wheel_zoom,zoom_in,zoom_out,box_zoom,undo,redo,reset,tap,save,box_select,poly_select,lasso_select\"\n",
        "p = figure(tools=TOOLS)\n",
        "p.hover.tooltips = [('Place', \"@place\"),('Country', \"@country\"),('Region', \"@region\")]\n",
        "p.scatter(x='x', y='y',fill_alpha=0.8,\n",
        "          color = colors,\n",
        "          line_color = None,\n",
        "          radius = 0.1,\n",
        "          source=d)\n",
        "show(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1_hSh8l-xGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's write our cluster numbers into the initial \"real data\"\n",
        "\n",
        "descr['cluster'] = clusterer.labels_\n",
        "cities['cluster'] = clusterer.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHP3y1dE-17_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we can try out some basic descriptive statistics\n",
        "\n",
        "descr.groupby('cluster').mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQjNTsH7_KgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Which cluster ranks lowest when it comes to the nomad score? And what are the cities in this cluster?\n",
        "\n",
        "cities[cities.cluster == 2].sort_values('nomad_score', ascending=True)['place'][:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4SC0Pz1coqn",
        "colab_type": "text"
      },
      "source": [
        "## Gig portfolios of online freelancers\n",
        "\n",
        "![alt text](http://sds-datacrunch.aau.dk/public/adult-alone-bar-1308625.jpg)\n",
        "\n",
        "You get gig-portfolio data for 1000 online freelancers ‚Äì overall ~35k gigs. Given this data can you identify professional patterns?\n",
        "\n",
        "This part of the tutorial is a short version based on the analysis performed for this paper:\n",
        "**Career Paths in Digital Marketplaces: Same, same but different?**\n",
        "With Mareike Seifried and Tobias Kretschmer\n",
        "LMU Munich\n",
        "Munich School of Management\n",
        "\n",
        " https://conference.druid.dk/acc_papers/48ox0g0vwmp0vvx8gj7lzwhbimflf0.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YlCnHBnvNmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading the data?\n",
        "data = pd.read_csv('http://sds-datacrunch.aau.dk/public/feelance_eda.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-06kXjWDi4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quick data exploration\n",
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1UASDJnYKBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPP8UOEfERbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How does one portfolio look like?\n",
        "data[data.f_id == 78].sub_category"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BgYMZ5pfSJT",
        "colab_type": "text"
      },
      "source": [
        "#### Assembling gig-portfolios from a gig-list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmKU47WygbJS",
        "colab_type": "text"
      },
      "source": [
        "A bit some thing on loops and slightly more advanced  stuff.\n",
        "\n",
        "the next couple of cells will show how you can \n",
        "- add stuff to lists and how to \n",
        "- work with loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMwHE05TZtRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "empty_list = []\n",
        "\n",
        "print(empty_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWRmCzkBZxLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "empty_list.append(1)\n",
        "\n",
        "print(empty_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_2IsbVYmtNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "empty_list.append(\"i don't want to be in that list\")\n",
        "\n",
        "print(empty_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRDtXXxznqhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "empty_list.append(['üôâ','üëΩ','üêº'])\n",
        "\n",
        "print(empty_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lag_wjvBn4ip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's get the panda out! --> 'üêº'\n",
        "empty_list[2][2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaLh4Xm3norE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "empty_list.extend(['üêß','üçÖ','ü§ò'])\n",
        "\n",
        "print(empty_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X36e713QoF7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LOOPS\n",
        "\n",
        "emoji_list = ['üôâ', 'üëΩ', 'üêº','üêß','üçÖ','ü§ò']\n",
        "\n",
        "\n",
        "for some_emoji in emoji_list:\n",
        "  print(50 * some_emoji)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDtA9s3uolC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LIST COMPREHENSIONS (mini-loops in Python)\n",
        "\n",
        "[50*x for x in emoji_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Dvi83HApZU",
        "colab_type": "text"
      },
      "source": [
        "From here we can try to assemble job-portfolios by making a list of lists with performed gigs for individual workers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyhVZukHbaG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# individual freelancers\n",
        "workers = data.f_id.unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HT8VMu1D0mL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create empty list\n",
        "stuff_people_do = []\n",
        "\n",
        "for some_worker_id in workers: #initiate loop\n",
        "  stuff = list(data[data.f_id == some_worker_id].sub_category) # extract portfolio for a single worker\n",
        "  stuff_people_do.append((some_worker_id, stuff)) # append portfolio to the list of portfolios"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD7-GNhvEHee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use pandas to make it into a datafrmae\n",
        "portfolios = pd.DataFrame(stuff_people_do, columns = ['f_id', 'gig_portfolio'])\n",
        "#Calculate the most common gig_activity\n",
        "portfolios['max'] = portfolios['gig_portfolio'].map(lambda t: max(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwpqsms0jD1L",
        "colab_type": "text"
      },
      "source": [
        "Feature extraction from lists and dictionaries\n",
        "A big part of Data Science is feature extraction ‚Äì producing data where is no \"traditional\" data. Much more on tha tin M2 and M3\n",
        "\n",
        "But for now: How can we produce tabular data from lists of jobs?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiA4MTSGjDN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_of_lists = [['cat','dog','dog','horse','tree'], ['cat','cat','dog'],['elephant','cat','horse', 'horse'] ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELELBKrUjrO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Packages for feature extraction\n",
        "from collections import Counter #helper package for counting stuff\n",
        "from sklearn.feature_extraction import DictVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaq9hzhYjwQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v = DictVectorizer(sparse=False)\n",
        "\n",
        "v.fit_transform([{'cat':2, 'dog':1},  # ['cat','cat','dog']\n",
        "                 {'cat':2, 'elephant':5}\n",
        "                 ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoXPk0IgkUeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is where Counter comes in\n",
        "Counter(['cat','cat','dog'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUvRS-cykaY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dicts = []\n",
        "for i in list_of_lists:\n",
        "  dicts.append(dict(Counter(i)))\n",
        "\n",
        "# Let's check:\n",
        "\n",
        "print(dicts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsFGWR_HkwF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array = v.fit_transform(dicts)\n",
        "print(array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idjFxSyzkzB5",
        "colab_type": "text"
      },
      "source": [
        "### Back to our job-portfolios\n",
        "\n",
        "Let's apply this feature-extraction approach:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ907EF7k-Fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dicts = []\n",
        "for i in portfolios['gig_portfolio']:\n",
        "  dicts.append(dict(Counter(i)))\n",
        "\n",
        "portfolio_matrix = v.fit_transform(dicts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIBG8eSUrGck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "portfolio_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6QOBLdGlMjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "portfolio_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT5VA5PZr2Og",
        "colab_type": "text"
      },
      "source": [
        "Why should I trust this? Can we check if all the transformations didn't mess up things?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipR4NJnyrS2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# portfolio of worker 0\n",
        "portfolio_matrix[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZTcwURUrX8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# what's the taks sub-category of index 3?\n",
        "v.feature_names_[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJie4th4rrqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How many times did the worker perform this gig?\n",
        "data[data.f_id == 1].sub_category"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTKYQtXtsRRh",
        "colab_type": "text"
      },
      "source": [
        "Now we sucessfully created \"Bag-of-Gigs\" representations of individual workers' portfolios\n",
        "The matrix is however very sparse, as we can see (many zeros and  only some non-0 values) as one would expect that.\n",
        "PCA is not a good choice here. Instead we will use Non-negative Matrix Factorization (NMF), which has the tendency to very well \"squash\" the data into interpretable latent themes:\n",
        "\n",
        "In Natural Language Processing, such themes are called topics and what we are going to do now is referred to as Vector Space Modelling or Topic Modelling\n",
        "\n",
        "The coolest thing about that identified components are very interopretable. This is because the model is build on assumptions about the world related to co-occurence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NylUni31F0Mj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try to bring it all the way down to 5 dimensions\n",
        "\n",
        "from sklearn.decomposition import NMF\n",
        "model = NMF(n_components=5)\n",
        "portfolio_matrix_reduced = model.fit_transform(portfolio_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REzpvIj8v2jG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# what are these components?\n",
        "model.components_.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmUWA_l_tRKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a dataframe\n",
        "components_df = pd.DataFrame(model.components_, columns=list(v.feature_names_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWMsj6YVe1lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "components_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOMmC4X5uHRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select a component\n",
        "component = components_df.iloc[0,:]\n",
        "\n",
        "# Print result of nlargest\n",
        "print(component.nlargest())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IXzZQoCGHIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import clustering and dimensionality reduction\n",
        "# HDBSCAN won't work with numpy < 1.16\n",
        "\n",
        "import hdbscan\n",
        "import umap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHdO-smggkkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try not to overdo things and maybe keep it at 20 components\n",
        "\n",
        "model = NMF(n_components=20)\n",
        "\n",
        "portfolio_matrix_reduced = model.fit_transform(portfolio_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whHcbboJGgUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note that the standard setting of UMAP will produce 2 dimensions\n",
        "embedding = umap.UMAP(n_neighbors=15, metric='cosine').fit_transform(portfolio_matrix_reduced)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skr-CvmOcYmH",
        "colab_type": "text"
      },
      "source": [
        "You can read more about\n",
        "\n",
        "\n",
        "- UMAP here: https://umap-learn.readthedocs.io/en/latest/\n",
        "- HDBSCAN here: https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html\n",
        "\n",
        "HDBSCAN is a recent hi-performance density based clustering approach\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xu8gU4eGvR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now, we will feed the 2-dimensional representation into HDBSCAN\n",
        "# Warning can be ignored for now\n",
        "\n",
        "clusterer = hdbscan.HDBSCAN(min_cluster_size=50, \n",
        "                            min_samples=50, \n",
        "                            leaf_size=40, \n",
        "                            #core_dist_n_jobs=16, \n",
        "                            prediction_data=True)\n",
        "clusterer.fit(embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxxuBFk0HopB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pal = sns.color_palette(\"Paired\", n_colors = len(set(clusterer.labels_)))[1:]\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.rcParams.update({'font.size': 15})\n",
        "clusterer.condensed_tree_.plot(select_clusters=True,\n",
        "                               selection_palette=pal, label_clusters=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg9vPbJbHqPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scatterplor of the UMAP embeddings with cluster-coloring\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "plt.figure(figsize=(10,10))\n",
        "g = sns.scatterplot(*embedding.T, \n",
        "                hue=clusterer.labels_, \n",
        "                legend='full',\n",
        "                palette = 'Paired')\n",
        "legend = g.get_legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF5KRnWamiBj",
        "colab_type": "text"
      },
      "source": [
        "### Let's quickly explore the clusters.\n",
        "Here we only look at the most common activities in the cluster. But certainly one could compare the identified communities on other dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l1TlEExymgUz",
        "colab": {}
      },
      "source": [
        "# Write community number into the initial dataset\n",
        "portfolios['cluster'] = clusterer.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91rsYFfzJqbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper tool for iteration, combinations etc https://docs.python.org/2/library/itertools.html\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW0uwlnVJsmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Link up the job portfolios of freelancer in cluster and count up how many times tasks have been performed.\n",
        "counter = Counter(list(itertools.chain(*portfolios[portfolios.cluster == 0]['gig_portfolio'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iJQm9MVJ2KY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Whow most common tasks\n",
        "counter.most_common(20)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}